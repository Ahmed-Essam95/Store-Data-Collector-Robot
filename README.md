# ğŸª Store-Data-Collector-Robot

An automated Selenium-powered bot that scrapes store details from a dynamic web portal, processes multi-page data, and saves it neatly into Excel using OpenPyXL.

---

## ğŸš€ Features

- ğŸ” **Automated login & navigation** â€” launches Chrome in headless mode and navigates securely through the store portal.  
- ğŸ§­ **Dynamic element handling** â€” interacts with buttons, text fields, and next-page logic via Selenium.  
- ğŸ“„ **Scrapes detailed store data** â€” collects area, type, code, location, status, opening times, and contact information.  
- ğŸ“Š **Excel integration (OpenPyXL)** â€” writes structured data into Excel with formatting and sequential numbering.  
- ğŸ” **Pagination automation** â€” automatically navigates through **all available pages** until the last page.  
- âš™ï¸ **Resilient architecture** â€” includes re-fetching, element checks, and smart delay handling for stability.  

---

## ğŸ§  Tech Stack

- **Python 3.x**
- **Selenium WebDriver**
- **OpenPyXL**
- **Headless Chrome (Options)**

---

## ğŸ§© How It Works

1. Loads target Excel file and initializes the Selenium WebDriver.  
2. Visits the main portal link and waits for store cards to load.  
3. Extracts store data fields one by one:
   - Area  
   - Store type and code  
   - Location  
   - Status (Open / Closed)  
   - Opening time details  
   - Contact & manager info  
4. Saves all data into the Excel file in real time.  
5. Continues through all pages until pagination ends.  

---

## ğŸ“ Output Example

Each row in Excel contains:
| Area | Type | Code | Location | Status | Opening | Contact | Manager | Page | Store No. |
|------|------|------|----------|---------|----------|----------|----------|--------|------------|

---

## ğŸ§‘â€ğŸ’» Author

**Ahmed Essam**  
Automation Engineer | Python Developer  

---

## ğŸ› ï¸ Future Enhancements

- Add screenshot capture for failed pages  
- Integrate progress logging system  
- Convert to `.exe` desktop tool for non-technical users  
